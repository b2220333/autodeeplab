{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified notebook to convert an image dataset with jpeg extension to TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.io as spio\n",
    "from matplotlib import pyplot as plt\n",
    "from imageio import imread\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializations -- setting up image directory and so on\n",
    "We don't have actual annoptations yet so ignore the we ignore it for now!\n",
    "When we do actual retraining we need such information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define base paths for dataset images\n",
    "base_dataset_dir = './'\n",
    "images_folder_name = \"images\"\n",
    "annotations_folder_name = \"images\"\n",
    "images_dir = os.path.join(base_dataset_dir, images_folder_name)\n",
    "annotations_dir = os.path.join(base_dataset_dir, annotations_folder_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of all images in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size: 635\n"
     ]
    }
   ],
   "source": [
    "images_filename_list = os.listdir(images_dir)\n",
    "np.random.shuffle(images_filename_list)\n",
    "test_images_filename_list = images_filename_list\n",
    "print(\"train set size:\", len(test_images_filename_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the directory that tfrecords need to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATASET_DIR=\"./deeplab_v3/dataset/tfrecords/\"\n",
    "if not os.path.exists(TEST_DATASET_DIR):\n",
    "    os.mkdir(TEST_DATASET_DIR)\n",
    "    \n",
    "TEST_FILE = 'test.tfrecords'\n",
    "test_writer = tf.python_io.TFRecordWriter(os.path.join(TEST_DATASET_DIR,TEST_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are not using this function probably for our project\n",
    "def read_annotation_from_mat_file(annotations_dir, image_name):\n",
    "    annotations_path = os.path.join(annotations_dir, (image_name.strip() + \".mat\"))\n",
    "    mat = spio.loadmat(annotations_path)\n",
    "    img = mat['GTcls']['Segmentation'][0][0]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main function to create TFRecords from image dataset\n",
    "Here, we also resize the images in the dataset to match the maximum dimension of 513x513 in the pretrained model.\n",
    "\n",
    "Resizining is done by preserving the aspect ratio of the original images usonhg OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfrecord_dataset(filename_list, writer):\n",
    "    HEIGHT = 512\n",
    "\n",
    "    # create training tfrecord\n",
    "    read_imgs_counter = 0\n",
    "    for i, image_name in enumerate(filename_list):\n",
    "\n",
    "        try:\n",
    "            image_npTMP = imread(os.path.join(images_dir, image_name.strip()))\n",
    "            ar = HEIGHT / image_npTMP.shape[1]\n",
    "            dim = (HEIGHT, int(image_npTMP.shape[0] * ar))\n",
    "            image_np = cv2.resize(image_npTMP, dim)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File:\",image_name.strip(),\"not found.\")\n",
    "            continue\n",
    "            \n",
    "        try:            \n",
    "            annotation_npTMP = imread(os.path.join(annotations_dir, image_name.strip()))[:,:,0]\n",
    "            annotation_np_Resize = cv2.resize(annotation_npTMP, dim)\n",
    "            ret,annotation_np = cv2.threshold(annotation_np_Resize,0.5,1,cv2.THRESH_BINARY)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File:\",image_name.strip(),\"not found.\")\n",
    "            continue\n",
    "            \n",
    "        read_imgs_counter += 1\n",
    "        image_h = image_np.shape[0]\n",
    "        image_w = image_np.shape[1]\n",
    "\n",
    "        img_raw = image_np.tostring()\n",
    "        annotation_raw = annotation_np.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                'height': _int64_feature(image_h),\n",
    "                'width': _int64_feature(image_w),\n",
    "                'image_raw': _bytes_feature(img_raw),\n",
    "                'annotation_raw': _bytes_feature(annotation_raw)}))\n",
    "\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    print(\"End of TfRecord. Total of image written:\", read_imgs_counter)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: Icon not found.\n",
      "End of TfRecord. Total of image written: 634\n"
     ]
    }
   ],
   "source": [
    "# create training dataset\n",
    "create_tfrecord_dataset(test_images_filename_list, test_writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
