{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, './deeplab_v3/')\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "import numpy as np\n",
    "import network\n",
    "slim = tf.contrib.slim\n",
    "import argparse\n",
    "import json\n",
    "from preprocessing.read_data import tf_record_parser, scale_image_with_crop_padding\n",
    "from preprocessing import training\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot pretty figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Saving the figures in Figs folder (If this folder does not exist already, this function will make Figs directory)\n",
    "FIGS_DIR = \"processed_images\"\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=150):\n",
    "    if not os.path.isdir(FIGS_DIR):\n",
    "        os.makedirs(FIGS_DIR)\n",
    "    path = os.path.join(\".\",FIGS_DIR, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, bbox_inches='tight', format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting pre-trained model for evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.interactive(False)\n",
    "parser = argparse.ArgumentParser()\n",
    "envarg = parser.add_argument_group('Eval params')\n",
    "envarg.add_argument(\"--model_id\", default=16645, type=int, help=\"Model id name to be loaded.\")\n",
    "log_folder = './deeplab_v3/tboard_logs'\n",
    "model_name = '16645'\n",
    "if not os.path.exists(os.path.join(log_folder, model_name, \"test\")):\n",
    "    os.makedirs(os.path.join(log_folder, model_name, \"test\"))\n",
    "\n",
    "with open(log_folder + '/' + model_name + '/train/data.json', 'r') as fp:\n",
    "    args = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up different category of objects in deeplab\n",
    "We just care about cars and one final touch that we can do is just keeping the object that are detectd as car --> category number 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dotdict(dict):\n",
    "     \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "     __getattr__ = dict.get\n",
    "     __setattr__ = dict.__setitem__\n",
    "     __delattr__ = dict.__delitem__\n",
    "\n",
    "args = Dotdict(args)\n",
    "\n",
    "# 0=background\n",
    "# 1=aeroplane\n",
    "# 2=bicycle\n",
    "# 3=bird\n",
    "# 4=boat\n",
    "# 5=bottle\n",
    "# 6=bus\n",
    "# 7=car\n",
    "# 8=cat\n",
    "# 9=chair\n",
    "# 10=cow\n",
    "# 11=diningtable\n",
    "# 12=dog\n",
    "# 13=horse\n",
    "# 14=motorbike\n",
    "# 15=person\n",
    "# 16=potted plant\n",
    "# 17=sheep\n",
    "# 18=sofa\n",
    "# 19=train\n",
    "# 20=tv/monitor\n",
    "# 255=unknown\n",
    "\n",
    "class_labels = [v for v in range((args.number_of_classes+1))]\n",
    "class_labels[-1] = 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Providing the directory and the filename for image dataset in TFRecords format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FOLDER = './deeplab_v3/tboard_logs'\n",
    "TEST_DATASET_DIR=\"./deeplab_v3/dataset/tfrecords\"\n",
    "TEST_FILE = 'test.tfrecords'\n",
    "\n",
    "test_filenames = [os.path.join(TEST_DATASET_DIR,TEST_FILE)]\n",
    "test_dataset = tf.data.TFRecordDataset(test_filenames)\n",
    "test_dataset = test_dataset.map(tf_record_parser)  # Parse the record into tensors.\n",
    "test_dataset = test_dataset.map(lambda image, annotation, image_shape: scale_image_with_crop_padding(image, annotation, image_shape, args.crop_size))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=100)\n",
    "test_dataset = test_dataset.batch(args.batch_size)\n",
    "\n",
    "iterator = test_dataset.make_one_shot_iterator()\n",
    "batch_images_tf, batch_labels_tf, batch_shapes_tf = iterator.get_next()\n",
    "\n",
    "logits_tf =  network.deeplab_v3(batch_images_tf, args, is_training=False, reuse=False)\n",
    "\n",
    "valid_labels_batch_tf, valid_logits_batch_tf = training.get_valid_logits_and_labels(\n",
    "    annotation_batch_tensor=batch_labels_tf,\n",
    "    logits_batch_tensor=logits_tf,\n",
    "    class_labels=class_labels)\n",
    "\n",
    "cross_entropies_tf = tf.nn.softmax_cross_entropy_with_logits_v2(logits=valid_logits_batch_tf,\n",
    "                                                                labels=valid_labels_batch_tf)\n",
    "\n",
    "cross_entropy_mean_tf = tf.reduce_mean(cross_entropies_tf)\n",
    "tf.summary.scalar('cross_entropy', cross_entropy_mean_tf)\n",
    "\n",
    "predictions_tf = tf.argmax(logits_tf, axis=3)\n",
    "probabilities_tf = tf.nn.softmax(logits_tf)\n",
    "\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "test_folder = os.path.join(log_folder, model_name, \"test\")\n",
    "train_folder = os.path.join(log_folder, model_name, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the pretrained model on the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Create a saver.\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, os.path.join(train_folder, \"model.ckpt\"))\n",
    "    print(\"Model\", model_name, \"restored.\")\n",
    "\n",
    "    mean_IoU = []\n",
    "    mean_pixel_acc = []\n",
    "    mean_freq_weighted_IU = []\n",
    "    mean_acc = []\n",
    "\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            batch_images_np, batch_predictions_np, batch_labels_np, batch_shapes_np, summary_string= sess.run([batch_images_tf, predictions_tf, batch_labels_tf, batch_shapes_tf, merged_summary_op])\n",
    "            heights, widths = batch_shapes_np\n",
    "\n",
    "            # loop through the images in the batch and extract the valid areas from the tensors\n",
    "            for i in range(batch_predictions_np.shape[0]):\n",
    "\n",
    "                label_image = batch_labels_np[i]\n",
    "                pred_image = batch_predictions_np[i]\n",
    "                input_image = batch_images_np[i]\n",
    "\n",
    "                indices = np.where(label_image != 255)\n",
    "                label_image = label_image[indices]\n",
    "                pred_image = pred_image[indices]\n",
    "                input_image = input_image[indices]\n",
    "                \n",
    "                print(label_image.shape)\n",
    "\n",
    "                if label_image.shape[0] == 262144:\n",
    "                    label_image = np.reshape(label_image, (512,512))\n",
    "                    pred_image = np.reshape(pred_image, (512,512))\n",
    "                    input_image = np.reshape(input_image, (512,512,3))\n",
    "                else:\n",
    "                    label_image = np.reshape(label_image, (heights[i], widths[i]))\n",
    "                    pred_image = np.reshape(pred_image, (heights[i], widths[i]))\n",
    "                    input_image = np.reshape(input_image, (heights[i], widths[i], 3))\n",
    "\n",
    "                pix_acc = pixel_accuracy(pred_image, label_image)\n",
    "                m_acc = mean_accuracy(pred_image, label_image)\n",
    "                IoU = mean_IU(pred_image, label_image)\n",
    "                freq_weighted_IU = frequency_weighted_IU(pred_image, label_image)\n",
    "\n",
    "                mean_pixel_acc.append(pix_acc)\n",
    "                mean_acc.append(m_acc)\n",
    "                mean_IoU.append(IoU)\n",
    "                mean_freq_weighted_IU.append(freq_weighted_IU)\n",
    "\n",
    "                f, (ax1, ax3) = plt.subplots(1, 2, figsize=(25, 25))\n",
    "\n",
    "                ax1.imshow(input_image.astype(np.uint8))\n",
    "                ax1.axis('off')\n",
    "#                 ax2.imshow(input_image.astype(np.uint8))\n",
    "#                 ax2.imshow(np.isin(pred_image, 7).astype(np.uint8), alpha=0.7)\n",
    "#                             \n",
    "                ax3.imshow(input_image.astype(np.uint8))\n",
    "                ax3.imshow(pred_image, alpha=0.7) \n",
    "                ax3.axis('off')\n",
    "        \n",
    "                save_fig(str(cnt))\n",
    "#                 plt.show()                \n",
    "                plt.close()\n",
    "                cnt += 1\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
